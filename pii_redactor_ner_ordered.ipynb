{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a96c75c",
   "metadata": {},
   "source": [
    "\n",
    "# PII Redactor (Transformers NER) — Ordered Compact Notebook\n",
    "\n",
    "**Order requested:**  \n",
    "1) Imports, setup, configs → 2) Pipeline loader & helpers → 3) Fine-tuning → 4) Run redaction  \n",
    "The final run prefers the **fine‑tuned** checkpoint if it exists; otherwise, it uses the **base** model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "415d306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "ALLOW_REGEX_STRUCTURED = False\n",
    "\n",
    "MODEL_NAME = \"Davlan/xlm-roberta-base-ner-hrl\"\n",
    "\n",
    "INPUT_PATH  = Path(\"input.txt\")\n",
    "OUTPUT_PATH = Path(\"output.txt\")\n",
    "CSV_PATH    = Path(\"redaction_comparison.csv\")\n",
    "\n",
    "FINETUNE_DIR = Path(\"finetuned-ner\")\n",
    "FINETUNE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "EMAIL_RE = PHONE_RE = URL_RE = IPV4_RE = None\n",
    "if ALLOW_REGEX_STRUCTURED:\n",
    "    EMAIL_RE = re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\")\n",
    "    PHONE_RE = re.compile(r\"(?<!\\d)(?:\\+?\\d[\\s()./\\-]*){7,15}\\d\")\n",
    "    URL_RE   = re.compile(r\"(?:https?://\\S+|www\\.\\S+)\")\n",
    "    IPV4_RE  = re.compile(r\"\\b(?:(?:25[0-5]|2[0-4]\\d|1?\\d?\\d)\\.){3}(?:25[0-5]|2[0-4]\\d|1?\\d?\\d)\\b\")\n",
    "\n",
    "\n",
    "TAG_MAP = {\n",
    "    \"PER\": \"PERSON\", \"PERSON\": \"PERSON\",\n",
    "    \"ORG\": \"ORG\", \"ORGANIZATION\": \"ORG\",\n",
    "    \"LOC\": \"ADDRESS\", \"GPE\": \"ADDRESS\", \"LOCATION\": \"ADDRESS\", \"MISC\": \"ADDRESS\",\n",
    "    \"DATE\": \"DATE\",\n",
    "}\n",
    "REPLACERS = {\n",
    "    \"PERSON\": \"[REDACTED:PERSON]\",\n",
    "    \"ORG\": \"[REDACTED:ORG]\",\n",
    "    \"ADDRESS\": \"[REDACTED:ADDRESS]\",\n",
    "    \"DATE\": \"[REDACTED:DATE]\",\n",
    "    \"EMAIL\": \"[REDACTED:EMAIL]\",\n",
    "    \"PHONE\": \"[REDACTED:PHONE]\",\n",
    "    \"URL\": \"[REDACTED:URL]\",\n",
    "    \"IP\": \"[REDACTED:IP]\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47308c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def load_ner_pipeline():\n",
    "   \n",
    "    use_path = FINETUNE_DIR if any(FINETUNE_DIR.glob(\"*\")) else MODEL_NAME\n",
    "    print(\"Loading NER from:\", use_path)\n",
    "    ner = pipeline(\"token-classification\", model=str(use_path), aggregation_strategy=\"simple\")\n",
    "    return ner, use_path\n",
    "\n",
    "def collect_spans(text, ner):\n",
    "  \n",
    "    ml_spans = []\n",
    "    for ent in ner(text):\n",
    "        label = TAG_MAP.get(ent.get(\"entity_group\", \"\"), None)\n",
    "        if not label:\n",
    "            continue\n",
    "        ml_spans.append((label, int(ent[\"start\"]), int(ent[\"end\"])))\n",
    "\n",
    "\n",
    "    rx_spans = []\n",
    "    if ALLOW_REGEX_STRUCTURED:\n",
    "        if EMAIL_RE:\n",
    "            for m in EMAIL_RE.finditer(text):\n",
    "                rx_spans.append((\"EMAIL\", m.start(), m.end()))\n",
    "        if PHONE_RE:\n",
    "            for m in PHONE_RE.finditer(text):\n",
    "                digits = re.sub(r\"\\D\", \"\", m.group(0))\n",
    "                if 7 <= len(digits) <= 15:\n",
    "                    rx_spans.append((\"PHONE\", m.start(), m.end()))\n",
    "        if URL_RE:\n",
    "            for m in URL_RE.finditer(text):\n",
    "                rx_spans.append((\"URL\", m.start(), m.end()))\n",
    "        if IPV4_RE:\n",
    "            for m in IPV4_RE.finditer(text):\n",
    "                rx_spans.append((\"IP\", m.start(), m.end()))\n",
    "    return ml_spans, rx_spans\n",
    "\n",
    "def redact_and_save(text, ml_spans, rx_spans):\n",
    "   \n",
    "    spans = sorted(ml_spans + rx_spans, key=lambda x: (x[1], x[2]))\n",
    "    merged = []\n",
    "    for lab, s, e in spans:\n",
    "        if merged and s <= merged[-1][2]:\n",
    "            prev_lab, ps, pe = merged[-1]\n",
    "            merged[-1] = (prev_lab, ps, max(pe, e))\n",
    "        else:\n",
    "            merged.append((lab, s, e))\n",
    "\n",
    "    chars = list(text)\n",
    "    for lab, s, e in reversed(merged):\n",
    "        tag = REPLACERS.get(lab, \"[REDACTED]\")\n",
    "        chars[s:e] = list(tag)\n",
    "    redacted_text = \"\".join(chars)\n",
    "\n",
    "    \n",
    "    orig_lines = text.splitlines()\n",
    "    red_lines  = redacted_text.splitlines()\n",
    "    while len(red_lines) < len(orig_lines): red_lines.append(\"\")\n",
    "    while len(orig_lines) < len(red_lines): orig_lines.append(\"\")\n",
    "    df = pd.DataFrame({\"line\": range(1, len(orig_lines)+1), \"input\": orig_lines, \"redacted\": red_lines})\n",
    "    OUTPUT_PATH.write_text(redacted_text, encoding=\"utf-8\")\n",
    "    df.to_csv(CSV_PATH, index=False)\n",
    "    return redacted_text, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30fc9d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/kblrj3c10fv8wymvkvn_nh7r0000gn/T/ipykernel_89477/1739132733.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.167000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fine-tuned checkpoint to: /Users/joshuaradzadlaon/vscode/schoolworks/LegalRewriter/finetuned-ner\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "toy_sentences = [\n",
    "    \"Jane Doe met ACME in London on 12 June 2024 .\",\n",
    "    \"Carlos visited New York City on 2023-05-17 for ACME Corp .\",\n",
    "]\n",
    "\n",
    "label_list = [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-DATE\", \"I-DATE\"]\n",
    "label_to_id = {l:i for i,l in enumerate(label_list)}\n",
    "id_to_label = {i:l for i,l in enumerate(label_list)}\n",
    "\n",
    "def annotate_sentence(sent):\n",
    "    words = sent.split()\n",
    "    tags = [\"O\"] * len(words)\n",
    "    for i,w in enumerate(words):\n",
    "        if w in {\"Jane\",\"Carlos\"}: tags[i] = \"B-PER\"\n",
    "        if w in {\"Doe\"}:           tags[i] = \"I-PER\"\n",
    "        if w in {\"ACME\"}:          tags[i] = \"B-ORG\"\n",
    "        if w in {\"Corp\"}:          tags[i] = \"I-ORG\"\n",
    "        if w in {\"New\"}:           tags[i] = \"B-LOC\"\n",
    "        if w in {\"York\",\"City\"}:   tags[i] = \"I-LOC\"\n",
    "        if w in {\"London\"}:        tags[i] = \"B-LOC\"\n",
    "        if w in {\"12\",\"June\",\"2024\",\"2023-05-17\"}:\n",
    "            tags[i] = \"B-DATE\" if w in {\"12\",\"2023-05-17\"} else \"I-DATE\"\n",
    "    return words, tags\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenized_examples = []\n",
    "for s in toy_sentences:\n",
    "    words, tags = annotate_sentence(s)\n",
    "    enc = tokenizer(words, is_split_into_words=True, truncation=True, return_offsets_mapping=False)\n",
    "    word_ids = enc.word_ids()\n",
    "    label_ids = []\n",
    "    for wi in word_ids:\n",
    "        label_ids.append(-100 if wi is None else label_to_id[tags[wi]])\n",
    "    enc[\"labels\"] = label_ids\n",
    "    tokenized_examples.append(enc)\n",
    "\n",
    "dataset = Dataset.from_dict({k:[d[k] for d in tokenized_examples] for k in tokenized_examples[0].keys()})\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(label_list), id2label=id_to_label, label2id=label_to_id)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(FINETUNE_DIR),\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds = np.argmax(predictions, axis=-1)\n",
    "    mask = labels != -100\n",
    "    acc = (preds[mask] == labels[mask]).mean() if mask.any() else 0.0\n",
    "    return {\"token_acc\": float(acc)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(str(FINETUNE_DIR))\n",
    "tokenizer.save_pretrained(str(FINETUNE_DIR))\n",
    "print(\"Saved fine-tuned checkpoint to:\", FINETUNE_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f6a446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NER from: finetuned-ner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: finetuned-ner\n",
      "Saved redacted text to: /Users/joshuaradzadlaon/vscode/schoolworks/LegalRewriter/output.txt\n",
      "Saved comparison CSV to: /Users/joshuaradzadlaon/vscode/schoolworks/LegalRewriter/redaction_comparison.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>input</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John A. Smith from Globex LLC will join on 202...</td>\n",
       "      <td>[REDACTED:ORG] from[REDACTED:ADDRESS] will joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Meeting venue: 742 Evergreen Terrace, Shelbyvi...</td>\n",
       "      <td>Meeting venue: 742[REDACTED:DATE],[REDACTED:DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alternate phone: +44 20 7946 0958; support ema...</td>\n",
       "      <td>Alternate phone: +44 20 7946 0958; support ema...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line                                              input  \\\n",
       "0     1  John A. Smith from Globex LLC will join on 202...   \n",
       "1     2  Meeting venue: 742 Evergreen Terrace, Shelbyvi...   \n",
       "2     3  Alternate phone: +44 20 7946 0958; support ema...   \n",
       "\n",
       "                                            redacted  \n",
       "0  [REDACTED:ORG] from[REDACTED:ADDRESS] will joi...  \n",
       "1  Meeting venue: 742[REDACTED:DATE],[REDACTED:DA...  \n",
       "2  Alternate phone: +44 20 7946 0958; support ema...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ner, used_model = load_ner_pipeline()\n",
    "text = INPUT_PATH.read_text(encoding=\"utf-8\")\n",
    "ml_spans, rx_spans = collect_spans(text, ner)\n",
    "redacted_text, df = redact_and_save(text, ml_spans, rx_spans)\n",
    "print(\"Model used:\", used_model)\n",
    "print(\"Saved redacted text to:\", OUTPUT_PATH.resolve())\n",
    "print(\"Saved comparison CSV to:\", CSV_PATH.resolve())\n",
    "df.head(50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
